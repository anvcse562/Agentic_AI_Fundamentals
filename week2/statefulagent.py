import json
import time
import os
from typing import List, TypedDict, Dict, Any, Optional

# --- SETUP ---
try:
    from openai import OpenAI
    from dotenv import load_dotenv
except ImportError:
    print("Please install required packages: pip install openai python-dotenv")
    exit(1)

load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    print("WARNING: OPENAI_API_KEY not found. Please set it in your .env file.")
    client = None
else:
    client = OpenAI(api_key=api_key)


# =============================================================================
# HELPER: LLM WRAPPER
# =============================================================================
def invoke_llm(
    system_prompt: str,
    user_prompt: str,
    model: str = "gpt-4o",
    json_mode: bool = False
) -> str:
    """Wrapper for OpenAI API calls with optional JSON enforcement."""
    if not client:
        return "Error: No API Key provided."

    print(f"   [LLM ({model})]: Processing...")

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]

    kwargs: Dict[str, Any] = {
        "model": model,
        "messages": messages,
        "temperature": 0.7,
    }

    if json_mode:
        kwargs["response_format"] = {"type": "json_object"}

    try:
        response = client.chat.completions.create(**kwargs)
        return response.choices[0].message.content
    except Exception as e:
        print(f"   [API Error]: {e}")
        return ""


# =============================================================================
# PATTERN: STATEFUL PLANNING (Travel Agent)
# =============================================================================

# 1. Define the State Schema

class PlanStep(TypedDict):
    step: str
    description: str


class PlanState(TypedDict):
    destination: str
    budget: int
    plan: List[PlanStep]          # The list of steps generated by the Planner
    current_step: int             # Tracks progress
    results: Dict[str, Any]       # Memory of tool outputs, keyed by step id
    error: Optional[str]          # For robustness


# 2. Define the Planner Node
def planner_node(state: PlanState) -> PlanState:
    print(f"\n[Planner] Generating plan for {state['destination']}...")

    system_prompt = """
You are a Travel Planner.
Output a JSON object with a key "steps" containing a list of exactly 3 objects.
Each object must have keys:
- "step": a short title string
- "description": a detailed string
Do not include any other top-level keys.
"""
    user_prompt = (
        f"Create a travel plan for {state['destination']} "
        f"with a budget of ${state['budget']}."
    )

    # Request JSON mode to ensure parseable output
    response = invoke_llm(system_prompt, user_prompt, json_mode=True)

    try:
        data = json.loads(response)
        steps = data.get("steps", [])
        # Ensure it's a list of dict-like objects with "step" and "description"
        normalized_steps: List[PlanStep] = []
        for s in steps:
            # Defensive: skip malformed items
            if not isinstance(s, dict):
                continue
            title = str(s.get("step", "")).strip()
            desc = str(s.get("description", "")).strip()
            if not title or not desc:
                continue
            normalized_steps.append({"step": title, "description": desc})
        state["plan"] = normalized_steps
        print(f"[Planner] Plan created: {state['plan']}")
    except json.JSONDecodeError:
        state["error"] = "Failed to parse plan"
        print("[Planner] Error: Invalid JSON response.")

    return state


# 3. Define the Executor Node
def executor_node(state: PlanState) -> PlanState:
    step_idx = state["current_step"]

    # Termination condition: All steps complete
    if step_idx >= len(state["plan"]):
        print("[Executor] All steps complete.")
        return state

    task = state["plan"][step_idx]
    print(f"[Executor] Executing Step {step_idx + 1}: {task}")

    try:
        # Simulate Tool Execution (Network/API call)
        # In a real app, you would route 'task' to a specific tool function here.

        # Simulated transient error logic for demonstration
        # Use the 'step' field for the retry check
        if step_idx == 1 and "retry" not in task["step"]:
            # Fake a failure on the second step to show robustness
            raise ValueError("Network Timeout (Simulated)")

        tool_output = f"Result for '{task['step']}': Success (Simulated Data)"
        time.sleep(0.5)  # Simulate latency

        # Update State (Success path)
        # IMPORTANT CHANGE: use a hashable key (string) instead of the dict itself
        step_key = f"step_{step_idx}_{task['step']}"
        state["results"][step_key] = {
            "task": task,
            "output": tool_output,
        }
        state["current_step"] += 1

    except ValueError as e:
        # Robustness: Log error and modify state to retry
        print(f"   [Error] {e}. Retrying step...")
        # Mark the step as a retry in its title
        task["step"] = task["step"] + " (retry)"
        # No increment of current_step here: we will re-run this same index

    # Recursive loop: Pass state to next iteration
    return executor_node(state)


# 4. Main Runner
def run_travel_agent():
    print("--- STARTING STATEFUL TRAVEL AGENT ---")
    initial_state: PlanState = {
        "destination": "Tokyo",
        "budget": 2000,
        "plan": [],
        "current_step": 0,
        "results": {},
        "error": None,
    }

    # Step 1: Plan
    state_after_plan = planner_node(initial_state)

    # Step 2: Execute (if planning succeeded)
    if not state_after_plan["error"]:
        final_state = executor_node(state_after_plan)
        print("\n--- FINAL STATE RESULTS ---")
        print(json.dumps(final_state["results"], indent=2))
    else:
        print("Agent failed during planning phase.")


if __name__ == "__main__":
    if client:
        run_travel_agent()
    else:
        print("Skipping execution: No OpenAI API Key found.")
