{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **E-commerce Agentic RAG & Evaluation**\n",
    "This notebook covers the end-to-end deployment and governance of a shopping assistant.\n",
    "\n",
    "### **Core Components:**\n",
    "* **RAG Setup**: ChromaDB with `products.json` catalog.\n",
    "* **Multi-Tool Agent**: Orchestration via `product_search` and `product_comparison`.\n",
    "* **LLM-as-a-Judge**: Evaluates RAG retrieval relevancy, correctness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic RAG for E-commerce: Orchestration & Evaluation\n",
    "This notebook demonstrates a production-grade Agentic RAG pipeline, featuring:\n",
    "* **Dynamic Retrieval**: Tools that query a vector database on-demand.\n",
    "* **Orchestration**: An agent that reasons through multi-step customer queries.\n",
    "* **Multi-hop Reasoning**: Connecting disparate product specs to form complex answers.\n",
    "* **Evaluations**: Using Arize Phoenix to log traces and run LLM-as-a-Judge relevancy checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARIZE_API_KEY=\"\"\n",
    "ARIZE_SPACE_ID=\"\"\n",
    "OPENAI_API_KEY=\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”­ OpenTelemetry Tracing Details ðŸ”­\n",
      "|  Arize Project: ecom-agent-eval-v4\n",
      "|  Span Processor: BatchSpanProcessor\n",
      "|  Collector Endpoint: otlp.arize.com\n",
      "|  Transport: gRPC\n",
      "|  Transport Headers: {'authorization': '****', 'api_key': '****', 'arize-space-id': '****', 'space_id': '****', 'arize-interface': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 1. SETUP & TRACING ---\n",
    "# !pip install -qqq arize-otel arize agno openai openinference-instrumentation-agno openinference-instrumentation-openai chromadb sentence-transformers arize-phoenix\n",
    "\n",
    "import os\n",
    "import json\n",
    "from getpass import getpass\n",
    "from datetime import datetime\n",
    "from arize.otel import register\n",
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "from openinference.instrumentation.agno import AgnoInstrumentor\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"ARIZE_SPACE_ID\"] = globals().get(\"ARIZE_SPACE_ID\") or getpass(\"ðŸ”‘ Enter your Arize Space ID: \")\n",
    "\n",
    "os.environ[\"ARIZE_API_KEY\"] = globals().get(\"ARIZE_API_KEY\") or getpass(\"ðŸ”‘ Enter your Arize API Key: \")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = globals().get(\"OPENAI_API_KEY\") or getpass(\"ðŸ”‘ Enter your OpenAI API Key: \")\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = globals().get(\"TAVILY_API_KEY\") or getpass(\"ðŸ”‘ Enter your Tavily API Key: \")\n",
    "    \n",
    "model_id = \"ecom-agent-eval-v4\"\n",
    "tracer_provider = register(\n",
    "    space_id=os.getenv(\"ARIZE_SPACE_ID\"),\n",
    "    api_key=os.getenv(\"ARIZE_API_KEY\"),\n",
    "    project_name=model_id,\n",
    "    set_global_tracer_provider=True\n",
    ")\n",
    "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)\n",
    "AgnoInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now itâ€™s time to make our `local_flavor` tool even smarter by giving it access to a rich database of travel destination insights. Weâ€™ll use ChromaDB as the vector database and a Sentence Transformer model to generate embeddings that allow the tool to find and retrieve the most relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install \"numpy<2\" torch \"transformers<5\" sentence-transformers chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Knowledge Base & Vector DB**\n",
    "We initialize ChromaDB using the `SentenceTransformerEmbeddingFunction` to avoid hardware acceleration errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-20 23:27:35.356058: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as ef\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Mock Catalog Data\n",
    "products = [\n",
    "    {\"product\": \"LiteProduct 1\", \"category\": \"Home Organization\", \"price\": \"$25\", \"rating\": \"4.5\", \"reviews\": \"120\", \"description\": \"Minimalist shelf.\", \"specs\": \"Plastic, 5kg limit\"},\n",
    "    {\"product\": \"MaxProduct 2\", \"category\": \"Home Organization\", \"price\": \"$45\", \"rating\": \"4.8\", \"reviews\": \"85\", \"description\": \"Heavy duty organizer.\", \"specs\": \"Steel, 20kg limit\"},\n",
    "    {\"product\": \"EcoBin\", \"category\": \"Waste Management\", \"price\": \"$15\", \"rating\": \"4.2\", \"reviews\": \"50\", \"description\": \"Recycled bin.\", \"specs\": \"10L\"}\n",
    "]\n",
    "\n",
    "# 2. Initialize Chroma with explicit Embedding Function\n",
    "emb_func = ef.SentenceTransformerEmbeddingFunction(model_name='all-MiniLM-L6-v2')\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(name=\"ecom_catalog\", embedding_function=emb_func)\n",
    "\n",
    "collection.add(\n",
    "    documents=[f\"{p['product']} in {p['category']}: {p['description']}\" for p in products],\n",
    "    metadatas=products,\n",
    "    ids=[f\"id_{i}\" for i in range(len(products))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as ef\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb.utils.embedding_functions as ef\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# 1. Single initialization of the embedding function\n",
    "emb_func = ef.SentenceTransformerEmbeddingFunction(model_name='all-MiniLM-L6-v2')\n",
    "# 2. Setup Client\n",
    "chroma_client = chromadb.Client() \n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=\"ecommerce_products\",\n",
    "    embedding_function=emb_func\n",
    ")\n",
    "\n",
    "def load_and_index_products():\n",
    "    \"\"\"Load and index e-commerce products into ChromaDB\"\"\"\n",
    "    with open('ecommerce_products.json', 'r') as f:\n",
    "        products = json.load(f)\n",
    "    \n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "    \n",
    "    for i, product in enumerate(products):\n",
    "        # Create rich text representation for embedding\n",
    "        text = f\"Product: {product['product']}. Category: {product['category']}. Description: {product['description']}. Specs: {product['specs']}. Price: {product['price']}. Rating: {product['rating']}.\"\n",
    "        \n",
    "        documents.append(text)\n",
    "        metadatas.append({\n",
    "            \"product\": product[\"product\"],\n",
    "            \"category\": product[\"category\"],\n",
    "            \"description\": product[\"description\"],\n",
    "            \"specs\": product[\"specs\"],\n",
    "            \"price\": product[\"price\"],\n",
    "            \"rating\": product[\"rating\"],\n",
    "            \"reviews\": product[\"reviews\"]\n",
    "        })\n",
    "        ids.append(f\"product_{i}\")\n",
    "    \n",
    "    # Add to ChromaDB collection\n",
    "    collection.upsert(\n",
    "        documents=documents,\n",
    "        metadatas=metadatas,\n",
    "        ids=ids\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Indexed {len(documents)} products in vector database\")\n",
    "    return len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Indexed 100 products in vector database\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "num_products = load_and_index_products()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Define Tools & Agent**\n",
    "Implementing your specific `product_search` and `product_comparison` tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agno.tools import tool\n",
    "from opentelemetry import trace\n",
    "from openinference.semconv.trace import SpanAttributes\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "\n",
    "tracer = trace.get_tracer(__name__)\n",
    "\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "emb_func = ef.SentenceTransformerEmbeddingFunction(model_name='all-MiniLM-L6-v2')\n",
    "\n",
    "# RAG Tool for product search\n",
    "@tool\n",
    "def product_search(query: str, category: str = None, price: str = None) -> str:\n",
    "    \"\"\"Search for products using semantic similarity from vector database.\n",
    "    Args:\n",
    "        query: The search keywords.\n",
    "        category: The product category.\n",
    "        price: The budget or price range (e.g., 'under $50').\n",
    "    \"\"\"\n",
    "    with tracer.start_as_current_span(name=\"RAG\", attributes={}) as span:\n",
    "        # Include price in the semantic search query\n",
    "        search_query = f\"{query} {category or ''} {price or ''}\".strip()\n",
    "        span.set_attribute(\"input_value\", search_query)\n",
    "        \n",
    "        # The rest of your code remains the same...\n",
    "        query_embedding = embedding_model.encode([search_query])\n",
    "        \n",
    "        results = collection.query(\n",
    "            query_embeddings=query_embedding,\n",
    "            n_results=3\n",
    "        )\n",
    "        \n",
    "        if not results or not results.get(\"documents\"):\n",
    "            return \"No matching products found. Try different keywords or categories.\"\n",
    "        \n",
    "        retrieved_docs = results[\"documents\"][0]\n",
    "        retrieved_meta = results[\"metadatas\"][0]\n",
    "        \n",
    "        # Format product recommendations\n",
    "        products_found = []\n",
    "        for doc, meta in zip(retrieved_docs, retrieved_meta):\n",
    "            product_info = f\"\"\"\n",
    "**{meta['product']}**\n",
    "- **Category**: {meta['category']}\n",
    "- **Price**: {meta['price']}\n",
    "- **Rating**: {meta['rating']} ({meta['reviews']})\n",
    "- **Description**: {meta['description']}\n",
    "- **Specs**: {meta['specs']}\n",
    "            \"\"\"\n",
    "            products_found.append(product_info.strip())\n",
    "        \n",
    "        response = f\"Found {len(products_found)} matching products:\\n\\n\" + \"\\n\\n\".join(products_found)\n",
    "        span.set_attribute(\"output_value\", response)\n",
    "        \n",
    "        return response\n",
    "\n",
    "@tool\n",
    "def product_comparison(products: str) -> str:\n",
    "    \"\"\"Compare multiple products based on features and pricing\"\"\"\n",
    "    product_list = [p.strip() for p in products.split(',')]\n",
    "    comparison = \"Product Comparison:\\n\\n\"\n",
    "    \n",
    "    for product_name in product_list:\n",
    "        results = collection.query(\n",
    "            query_embeddings=embedding_model.encode([product_name]),\n",
    "            n_results=1\n",
    "        )\n",
    "        \n",
    "        if results[\"metadatas\"] and results[\"metadatas\"][0]:\n",
    "            meta = results[\"metadatas\"][0][0]\n",
    "            comparison += f\"**{meta['product']}**: {meta['price']} | {meta['rating']}â˜… | {meta['category']}\\n\"\n",
    "    \n",
    "    return comparison if len(product_list) > 1 else \"Please specify multiple products to compare.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# you must update the tools list in your Agent definition to include adaptive_search: tools=[product_search, product_comparison, adaptive_search]\n",
    "@tool\n",
    "def adaptive_search(query: str, budget: float = None) -> str:\n",
    "    \"\"\"\n",
    "    Search for products with a fallback mechanism if no products meet the budget.\n",
    "    Args:\n",
    "        query: Search keywords.\n",
    "        budget: Maximum price filter (numeric).\n",
    "    \"\"\"\n",
    "    # 1. Primary Search\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    results = collection.query(\n",
    "        query_embeddings=query_embedding,\n",
    "        n_results=5\n",
    "    )\n",
    "    \n",
    "    # 2. Filter by budget if provided\n",
    "    matches = []\n",
    "    if budget and results.get(\"metadatas\"):\n",
    "        for meta in results[\"metadatas\"][0]:\n",
    "            # Clean price string (e.g., \"$45\" -> 45.0)\n",
    "            price_val = float(meta['price'].replace('$', '').replace(',', ''))\n",
    "            if price_val <= budget:\n",
    "                matches.append(meta)\n",
    "    else:\n",
    "        matches = results.get(\"metadatas\", [[]])[0]\n",
    "\n",
    "    # 3. Fallback logic: Broaden search if no matches found\n",
    "    if not matches:\n",
    "        print(\"âš ï¸ No matches in budget. Falling back to broad electronics search.\")\n",
    "        fallback_results = collection.query(\n",
    "            query_embeddings=embedding_model.encode([\"electronics\"]),\n",
    "            n_results=3\n",
    "        )\n",
    "        matches = fallback_results.get(\"metadatas\", [[]])[0]\n",
    "\n",
    "    \n",
    "    response = \"Found the following results:\\n\"\n",
    "    for m in matches:\n",
    "        response += f\"- {m['product']} ({m['price']}): {m['description']}\\n\"\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– E-commerce Q&A Agent Ready!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a7e6ee21e740ac8d7fafe47de2e87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create E-commerce Q&A Agent\n",
    "ecommerce_agent = Agent(\n",
    "    name=\"EcommerceQA\",\n",
    "    role=\"AI E-commerce Assistant\",\n",
    "    model=OpenAIChat(id=\"gpt-4o\"),\n",
    "    instructions=(\n",
    "        \"You are a helpful e-commerce shopping assistant. \"\n",
    "        \"Use product_search to find relevant products and product_comparison for comparisons. \"\n",
    "        \"Answer naturally, recommend based on customer needs, and highlight key features, pricing, and ratings. \"\n",
    "        \"Keep responses concise and helpful under 800 words.\"\n",
    "    ),\n",
    "    markdown=True,\n",
    "    tools=[product_search, product_comparison],\n",
    ")\n",
    "\n",
    "# Test the agent\n",
    "query = \"\"\"\n",
    "Recommend products for home organization under $50.\n",
    "Also compare LiteProduct 1 vs MaxProduct 2.\n",
    "\"\"\"\n",
    "\n",
    "print(\"ðŸ¤– E-commerce Q&A Agent Ready!\")\n",
    "ecommerce_agent.print_response(query, stream=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Execution & Multi-hop Reasoning\n",
    "The query below requires the agent to find a product category, retrieve specific specs, and evaluate them against a battery requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunOutput(run_id='befcf277-2709-4339-ba3d-4192e3bd6030', agent_id='ecommerceqa', agent_name='EcommerceQA', session_id='eca46ba8-6e3e-4cfc-b71c-c61eeed33eca', parent_run_id=None, workflow_id=None, user_id=None, input=RunInput(input_content='Recommend tablets or smartphones for media consumption under $450 with at least 40h battery?', images=None, videos=None, audios=None, files=None), content='Here are some great options for tablets and smartphones suitable for media consumption under $450, all featuring a long battery life of at least 40 hours:\\n\\n1. **PremiumTablet 96**\\n   - **Price**: $420\\n   - **Rating**: 4.6/5 from 138 reviews\\n   - **Features**: Designed for media consumption and note-taking with a 1080p resolution and USB-C connectivity.\\n   - **Highlight**: Ideal for those who prioritize multimedia capabilities and a high level of performance.\\n\\n2. **LiteSmartphone 11**\\n   - **Price**: $280\\n   - **Rating**: 4.2/5 from 150 reviews\\n   - **Features**: This smartphone comes with a 1080p display and is lightweight, perfect for everyday use and communication.\\n   - **Highlight**: Best suited for users who want a budget-friendly option for regular communication and media consumption.\\n\\n3. **AdvancedTablet 7**\\n   - **Price**: $320\\n   - **Rating**: 4.6/5 from 175 reviews\\n   - **Features**: Offers an advanced display with 8K resolution, along with USB-C connectivity.\\n   - **Highlight**: Great for those looking for cutting-edge display technology in a tablet.\\n\\nEach of these options provides ample battery life to support prolonged media usage without frequent charging. If display quality and multimedia performance are your top priorities, \"PremiumTablet 96\" might be the best fit. For a more budget-conscious choice that still supports decent media features, consider \"LiteSmartphone 11\". If you want the latest display tech in a tablet, \"AdvancedTablet 7\" could be ideal.', content_type='str', reasoning_content=None, reasoning_steps=None, reasoning_messages=None, model_provider_data={'id': 'chatcmpl-DCJQgEDw2bldjyuct3FLM1BEIwgq6', 'system_fingerprint': 'fp_64dfa806c7'}, model='gpt-4o', model_provider='OpenAI', messages=[Message(id='9e37ea00-de24-44e9-9e37-1c291e573d9a', role='system', content='<your_role>\\nAI E-commerce Assistant\\n</your_role>\\n\\nYou are a helpful e-commerce shopping assistant. Use product_search to find relevant products and product_comparison for comparisons. Answer naturally, recommend based on customer needs, and highlight key features, pricing, and ratings. Keep responses concise and helpful under 800 words.\\n\\n<additional_information>\\n- Use markdown to format your answers.\\n</additional_information>', compressed_content=None, name=None, tool_call_id=None, tool_calls=None, audio=None, images=None, videos=None, files=None, audio_output=None, image_output=None, video_output=None, file_output=None, redacted_reasoning_content=None, provider_data=None, citations=None, reasoning_content=None, tool_name=None, tool_args=None, tool_call_error=None, stop_after_tool_call=False, add_to_agent_memory=True, from_history=False, metrics=Metrics(input_tokens=0, output_tokens=0, total_tokens=0, cost=None, audio_input_tokens=0, audio_output_tokens=0, audio_total_tokens=0, cache_read_tokens=0, cache_write_tokens=0, reasoning_tokens=0, timer=None, time_to_first_token=None, duration=None, provider_metrics=None, additional_metrics=None), references=None, created_at=1771793143, temporary=False), Message(id='8a72f644-245f-4602-8a83-1e03851492fa', role='user', content='Recommend tablets or smartphones for media consumption under $450 with at least 40h battery?', compressed_content=None, name=None, tool_call_id=None, tool_calls=None, audio=None, images=None, videos=None, files=None, audio_output=None, image_output=None, video_output=None, file_output=None, redacted_reasoning_content=None, provider_data=None, citations=None, reasoning_content=None, tool_name=None, tool_args=None, tool_call_error=None, stop_after_tool_call=False, add_to_agent_memory=True, from_history=False, metrics=Metrics(input_tokens=0, output_tokens=0, total_tokens=0, cost=None, audio_input_tokens=0, audio_output_tokens=0, audio_total_tokens=0, cache_read_tokens=0, cache_write_tokens=0, reasoning_tokens=0, timer=None, time_to_first_token=None, duration=None, provider_metrics=None, additional_metrics=None), references=None, created_at=1771793143, temporary=False), Message(id='6f91b138-ac5a-4015-9398-fdeafe9dd00d', role='assistant', content=None, compressed_content=None, name=None, tool_call_id=None, tool_calls=[{'id': 'call_BKwKbUusEjc4tpedcC2CHsWn', 'function': {'arguments': '{\"query\":\"tablets or smartphones for media consumption under $450 with long battery life\",\"category\":\"electronics\"}', 'name': 'product_search'}, 'type': 'function'}], audio=None, images=None, videos=None, files=None, audio_output=None, image_output=None, video_output=None, file_output=None, redacted_reasoning_content=None, provider_data={'id': 'chatcmpl-DCJQcUgzZdZgHE015leYEftQgausS', 'system_fingerprint': 'fp_a9a5a50c8d'}, citations=None, reasoning_content=None, tool_name=None, tool_args=None, tool_call_error=None, stop_after_tool_call=False, add_to_agent_memory=True, from_history=False, metrics=Metrics(input_tokens=174, output_tokens=31, total_tokens=205, cost=None, audio_input_tokens=0, audio_output_tokens=0, audio_total_tokens=0, cache_read_tokens=0, cache_write_tokens=0, reasoning_tokens=0, timer=None, time_to_first_token=None, duration=None, provider_metrics=None, additional_metrics=None), references=None, created_at=1771793143, temporary=False), Message(id='6883e2f0-c4a9-4844-9ff7-03d122192c9f', role='tool', content='Found 3 matching products:\\n\\n**PremiumTablet 96**\\n- **Category**: Electronics\\n- **Price**: $420\\n- **Rating**: 4.6 (138)\\n- **Description**: Premium tablet for media consumption and noteâ€‘taking.\\n- **Specs**: 1080p resolution, 40h battery, USBâ€‘C\\n\\n**LiteSmartphone 11**\\n- **Category**: Electronics\\n- **Price**: $280\\n- **Rating**: 4.2 (150)\\n- **Description**: Lightweight smartphone for everyday communication.\\n- **Specs**: 1080p display, 40h battery, USBâ€‘C\\n\\n**AdvancedTablet 7**\\n- **Category**: Electronics\\n- **Price**: $320\\n- **Rating**: 4.6 (175)\\n- **Description**: High-end tablet with advanced display technology.\\n- **Specs**: 8K resolution, 40h battery, USBâ€‘C', compressed_content=None, name=None, tool_call_id='call_BKwKbUusEjc4tpedcC2CHsWn', tool_calls=None, audio=None, images=None, videos=None, files=None, audio_output=None, image_output=None, video_output=None, file_output=None, redacted_reasoning_content=None, provider_data=None, citations=None, reasoning_content=None, tool_name='product_search', tool_args={'query': 'tablets or smartphones for media consumption under $450 with long battery life', 'category': 'electronics'}, tool_call_error=False, stop_after_tool_call=False, add_to_agent_memory=True, from_history=False, metrics=Metrics(input_tokens=0, output_tokens=0, total_tokens=0, cost=None, audio_input_tokens=0, audio_output_tokens=0, audio_total_tokens=0, cache_read_tokens=0, cache_write_tokens=0, reasoning_tokens=0, timer=None, time_to_first_token=None, duration=None, provider_metrics=None, additional_metrics=None), references=None, created_at=1771793146, temporary=False), Message(id='006c80cf-2a49-4698-ab9f-a99ee80c7942', role='assistant', content='Here are some great options for tablets and smartphones suitable for media consumption under $450, all featuring a long battery life of at least 40 hours:\\n\\n1. **PremiumTablet 96**\\n   - **Price**: $420\\n   - **Rating**: 4.6/5 from 138 reviews\\n   - **Features**: Designed for media consumption and note-taking with a 1080p resolution and USB-C connectivity.\\n   - **Highlight**: Ideal for those who prioritize multimedia capabilities and a high level of performance.\\n\\n2. **LiteSmartphone 11**\\n   - **Price**: $280\\n   - **Rating**: 4.2/5 from 150 reviews\\n   - **Features**: This smartphone comes with a 1080p display and is lightweight, perfect for everyday use and communication.\\n   - **Highlight**: Best suited for users who want a budget-friendly option for regular communication and media consumption.\\n\\n3. **AdvancedTablet 7**\\n   - **Price**: $320\\n   - **Rating**: 4.6/5 from 175 reviews\\n   - **Features**: Offers an advanced display with 8K resolution, along with USB-C connectivity.\\n   - **Highlight**: Great for those looking for cutting-edge display technology in a tablet.\\n\\nEach of these options provides ample battery life to support prolonged media usage without frequent charging. If display quality and multimedia performance are your top priorities, \"PremiumTablet 96\" might be the best fit. For a more budget-conscious choice that still supports decent media features, consider \"LiteSmartphone 11\". If you want the latest display tech in a tablet, \"AdvancedTablet 7\" could be ideal.', compressed_content=None, name=None, tool_call_id=None, tool_calls=None, audio=None, images=None, videos=None, files=None, audio_output=None, image_output=None, video_output=None, file_output=None, redacted_reasoning_content=None, provider_data={'id': 'chatcmpl-DCJQgEDw2bldjyuct3FLM1BEIwgq6', 'system_fingerprint': 'fp_64dfa806c7'}, citations=None, reasoning_content=None, tool_name=None, tool_args=None, tool_call_error=None, stop_after_tool_call=False, add_to_agent_memory=True, from_history=False, metrics=Metrics(input_tokens=416, output_tokens=352, total_tokens=768, cost=None, audio_input_tokens=0, audio_output_tokens=0, audio_total_tokens=0, cache_read_tokens=0, cache_write_tokens=0, reasoning_tokens=0, timer=None, time_to_first_token=None, duration=None, provider_metrics=None, additional_metrics=None), references=None, created_at=1771793146, temporary=False)], metrics=Metrics(input_tokens=590, output_tokens=383, total_tokens=973, cost=None, audio_input_tokens=0, audio_output_tokens=0, audio_total_tokens=0, cache_read_tokens=0, cache_write_tokens=0, reasoning_tokens=0, timer=<agno.utils.timer.Timer object at 0x1b4eef590>, time_to_first_token=2.9210733649961185, duration=7.890739890994155, provider_metrics=None, additional_metrics=None), additional_input=None, tools=[ToolExecution(tool_call_id='call_BKwKbUusEjc4tpedcC2CHsWn', tool_name='product_search', tool_args={'query': 'tablets or smartphones for media consumption under $450 with long battery life', 'category': 'electronics'}, tool_call_error=False, result='Found 3 matching products:\\n\\n**PremiumTablet 96**\\n- **Category**: Electronics\\n- **Price**: $420\\n- **Rating**: 4.6 (138)\\n- **Description**: Premium tablet for media consumption and noteâ€‘taking.\\n- **Specs**: 1080p resolution, 40h battery, USBâ€‘C\\n\\n**LiteSmartphone 11**\\n- **Category**: Electronics\\n- **Price**: $280\\n- **Rating**: 4.2 (150)\\n- **Description**: Lightweight smartphone for everyday communication.\\n- **Specs**: 1080p display, 40h battery, USBâ€‘C\\n\\n**AdvancedTablet 7**\\n- **Category**: Electronics\\n- **Price**: $320\\n- **Rating**: 4.6 (175)\\n- **Description**: High-end tablet with advanced display technology.\\n- **Specs**: 8K resolution, 40h battery, USBâ€‘C', metrics=Metrics(input_tokens=0, output_tokens=0, total_tokens=0, cost=None, audio_input_tokens=0, audio_output_tokens=0, audio_total_tokens=0, cache_read_tokens=0, cache_write_tokens=0, reasoning_tokens=0, timer=None, time_to_first_token=None, duration=None, provider_metrics=None, additional_metrics=None), child_run_id=None, stop_after_tool_call=False, created_at=1771793146, requires_confirmation=None, confirmed=None, confirmation_note=None, requires_user_input=None, user_input_schema=None, user_feedback_schema=None, answered=None, external_execution_required=None, external_execution_silent=None, approval_type=None)], images=None, videos=None, audio=None, files=None, response_audio=None, citations=None, references=None, metadata=None, session_state={'current_session_id': 'eca46ba8-6e3e-4cfc-b71c-c61eeed33eca', 'current_run_id': 'befcf277-2709-4339-ba3d-4192e3bd6030'}, created_at=1771792297, events=None, status=<RunStatus.completed: 'COMPLETED'>, requirements=None, workflow_step_id=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecommerce_agent.run(\"Recommend tablets or smartphones for media consumption under $450 with at least 40h battery?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Evals - System and Model Evals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![My Image](images/Untitled20.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Untitled20.png\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![My Image](images/Untitled21.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"Recommend products for home organization under $50. Also compare LiteProduct 1 vs MaxProduct 2\",\n",
    "    \"Suggest the best smart home devices under $200. Prioritize locks and thermostats with ratings above 4.5\",\n",
    "    \"Find top audio devices with active noise cancellation under $150 and at least 100 reviews\",\n",
    "    \"Recommend laptops or desktops for heavy multitasking with SSD > 1TB and rating above 4.5\",\n",
    "    \"Show fitness equipment for home workouts under $400, and compare UltraBike 19 vs EssentialBike 69\",\n",
    "    \"List eco-friendly products across any category under $60 and sort by rating\",\n",
    "    \"Recommend tablets or smartphones for media consumption under $450 with at least 40h battery\",\n",
    "    \"Find premium projectors for home theater under $700 and explain differences between MaxProjector 68, SmartProjector 15, and PremiumProjector 16\",\n",
    "    \"Suggest beauty kits or tools under $50 for daily routines with ratings above 4.3\",\n",
    "    \"Recommend wearable accessories for everyday use under $80, focusing on PremiumAccessory 32 and MaxAccessory 97\",\n",
    "    \"Find smart locks and cameras for an apartment security setup under $300 total budget\",\n",
    "    \"Recommend beginner-friendly books related to kits and tools under $30 and at least 40 reviews\",\n",
    "    \"Suggest audio products suitable for long battery life (â‰¥40h) under $200\",\n",
    "    \"Find computing devices (laptops, desktops, workstations, servers) sorted by price-to-RAM value\",\n",
    "    \"Recommend a starter home office setup with one computing device, one peripheral kit, and one office accessory, total under $1500\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"Recommend products for home organization under $50. Also compare LiteProduct 1 vs MaxProduct 2\",\n",
    "    \"Suggest the best smart home devices under $200. Prioritize locks and thermostats with ratings above 4.5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in queries:\n",
    "  response = ecommerce_agent.run(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Installing arize SDK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arize<8.0.0,>=7.1.0 (from arize[Tracing]<8.0.0,>=7.1.0)\n",
      "  Downloading arize-7.52.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.51.0 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from arize<8.0.0,>=7.1.0->arize[Tracing]<8.0.0,>=7.1.0) (1.66.0)\n",
      "Requirement already satisfied: pandas<3,>=0.25.3 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from arize<8.0.0,>=7.1.0->arize[Tracing]<8.0.0,>=7.1.0) (2.2.3)\n",
      "Requirement already satisfied: protobuf<7,>=4.21.0 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from arize<8.0.0,>=7.1.0->arize[Tracing]<8.0.0,>=7.1.0) (5.29.6)\n",
      "Requirement already satisfied: pyarrow>=0.15.0 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from arize<8.0.0,>=7.1.0->arize[Tracing]<8.0.0,>=7.1.0) (19.0.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.0.0 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from arize<8.0.0,>=7.1.0->arize[Tracing]<8.0.0,>=7.1.0) (2.10.6)\n",
      "Collecting requests-futures==1.0.0 (from arize<8.0.0,>=7.1.0->arize[Tracing]<8.0.0,>=7.1.0)\n",
      "  Downloading requests_futures-1.0.0-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: tqdm<5,>=4.60.0 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from arize<8.0.0,>=7.1.0->arize[Tracing]<8.0.0,>=7.1.0) (4.67.1)\n",
      "Requirement already satisfied: requests>=1.2.0 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from requests-futures==1.0.0->arize<8.0.0,>=7.1.0->arize[Tracing]<8.0.0,>=7.1.0) (2.32.3)\n",
      "Requirement already satisfied: deprecated in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from arize[Tracing]<8.0.0,>=7.1.0) (1.2.18)\n",
      "Requirement already satisfied: openinference-semantic-conventions<1,>=0.1.12 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from arize[Tracing]<8.0.0,>=7.1.0) (0.1.26)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions<1,>=0.43b0 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from arize[Tracing]<8.0.0,>=7.1.0) (0.60b1)\n",
      "Requirement already satisfied: opentelemetry-api==1.39.1 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from opentelemetry-semantic-conventions<1,>=0.43b0->arize[Tracing]<8.0.0,>=7.1.0) (1.39.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from opentelemetry-semantic-conventions<1,>=0.43b0->arize[Tracing]<8.0.0,>=7.1.0) (4.15.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from opentelemetry-api==1.39.1->opentelemetry-semantic-conventions<1,>=0.43b0->arize[Tracing]<8.0.0,>=7.1.0) (8.5.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from pandas<3,>=0.25.3->arize<8.0.0,>=7.1.0->arize[Tracing]<8.0.0,>=7.1.0) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from pandas<3,>=0.25.3->arize<8.0.0,>=7.1.0->arize[Tracing]<8.0.0,>=7.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from pandas<3,>=0.25.3->arize<8.0.0,>=7.1.0->arize[Tracing]<8.0.0,>=7.1.0) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from pandas<3,>=0.25.3->arize<8.0.0,>=7.1.0->arize[Tracing]<8.0.0,>=7.1.0) (2025.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->arize<8.0.0,>=7.1.0->arize[Tracing]<8.0.0,>=7.1.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->arize<8.0.0,>=7.1.0->arize[Tracing]<8.0.0,>=7.1.0) (2.27.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from deprecated->arize[Tracing]<8.0.0,>=7.1.0) (1.17.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3,>=0.25.3->arize<8.0.0,>=7.1.0->arize[Tracing]<8.0.0,>=7.1.0) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from requests>=1.2.0->requests-futures==1.0.0->arize<8.0.0,>=7.1.0->arize[Tracing]<8.0.0,>=7.1.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from requests>=1.2.0->requests-futures==1.0.0->arize<8.0.0,>=7.1.0->arize[Tracing]<8.0.0,>=7.1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from requests>=1.2.0->requests-futures==1.0.0->arize<8.0.0,>=7.1.0->arize[Tracing]<8.0.0,>=7.1.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from requests>=1.2.0->requests-futures==1.0.0->arize<8.0.0,>=7.1.0->arize[Tracing]<8.0.0,>=7.1.0) (2025.1.31)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/madmax_jos/Documents/agentaicourse/venv/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api==1.39.1->opentelemetry-semantic-conventions<1,>=0.43b0->arize[Tracing]<8.0.0,>=7.1.0) (3.21.0)\n",
      "Downloading arize-7.52.0-py3-none-any.whl (238 kB)\n",
      "Downloading requests_futures-1.0.0-py2.py3-none-any.whl (7.4 kB)\n",
      "Installing collected packages: requests-futures, arize\n",
      "  Attempting uninstall: requests-futures\n",
      "    Found existing installation: requests-futures 1.0.2\n",
      "    Uninstalling requests-futures-1.0.2:\n",
      "      Successfully uninstalled requests-futures-1.0.2\n",
      "  Attempting uninstall: arize\n",
      "    Found existing installation: arize 8.2.1\n",
      "    Uninstalling arize-8.2.1:\n",
      "      Successfully uninstalled arize-8.2.1\n",
      "Successfully installed arize-7.52.0 requests-futures-1.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "#### arize SDK installed!\n",
      "\u001b[38;21m  arize.utils.logging | INFO | Creating named session as 'python-sdk-arize_python_export_client-c7253f78-f4c3-4d03-91cb-88909eb05630'.\u001b[0m\n",
      "#### Exporting your primary dataset into a dataframe.\n",
      "\u001b[38;21m  arize.utils.logging | INFO | Fetching data...\u001b[0m\n",
      "\u001b[38;21m  arize.utils.logging | INFO | Starting exporting...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  exporting 46 rows: 100%|\u001b[38;2;0;128;0mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 46/46 [00:00, 231.21 row/s]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('#### Installing arize SDK')\n",
    "\n",
    "! pip install \"arize[Tracing]>=7.1.0, <8.0.0\"\n",
    "\n",
    "print('#### arize SDK installed!')\n",
    "\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from arize.exporter import ArizeExportClient\n",
    "from arize.utils.types import Environments\n",
    "\n",
    "client = ArizeExportClient()\n",
    "\n",
    "print('#### Exporting your primary dataset into a dataframe.')\n",
    "\n",
    "\n",
    "\n",
    "primary_df = client.export_model_to_df(\n",
    "    space_id='U3BhY2U6MzgyNDg6V1Q0Lw==',\n",
    "    model_id='ecom-agent-eval-v4',\n",
    "    environment=Environments.TRACING,\n",
    "    start_time=datetime.fromisoformat('2026-02-13T05:00:00.000+00:00'),\n",
    "    end_time=datetime.fromisoformat('2026-02-21T04:59:59.999+00:00'),\n",
    "    # Optionally specify columns to improve query performance\n",
    "    # columns=['context.span_id', 'attributes.llm.input']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['attributes.llm.token_count.completion_details.output', 'event.names',\n",
       "       'attributes.exception.type', 'attributes.llm.prompt_template.version',\n",
       "       'attributes.retrieval.documents', 'parent_id',\n",
       "       'attributes.llm.cost.completion_details.audio', 'time',\n",
       "       'attributes.agno.agent', 'attributes.llm.token_count.prompt',\n",
       "       'attributes.llm.cost.prompt', 'attributes.embedding.model_name',\n",
       "       'attributes.llm.prompt_template.template', 'name',\n",
       "       'attributes.openinference.span.kind', 'attributes.exception.stacktrace',\n",
       "       'attributes.input.value', 'attributes.reranker.query',\n",
       "       'attributes.llm.token_count.completion_details.audio',\n",
       "       'attributes.llm.provider',\n",
       "       'attributes.llm.cost.prompt_details.cache_read',\n",
       "       'attributes.llm.cost.completion_details.reasoning',\n",
       "       'attributes.llm.cost.completion_details.output',\n",
       "       'attributes.llm.token_count.total', 'attributes.output.mime_type',\n",
       "       'attributes.reranker.model_name',\n",
       "       'attributes.llm.token_count.prompt_details.audio',\n",
       "       'attributes.llm.invocation_parameters', 'attributes.llm.system',\n",
       "       'attributes.agno.run.id', 'attributes.llm.token_count.completion',\n",
       "       'events', 'status_code', 'latency_ms', 'end_time',\n",
       "       'attributes.input.mime_type',\n",
       "       'attributes.llm.token_count.prompt_details.cache_read',\n",
       "       'context.trace_id', 'attributes.llm.prompt_template.variables',\n",
       "       'attributes.graph.node.name', 'context.span_id', 'attributes.tool.name',\n",
       "       'attributes.llm.cost.completion',\n",
       "       'attributes.llm.cost.prompt_details.input', 'attributes.agno.agent.id',\n",
       "       'attributes.output.value', 'attributes.llm.cost.prompt_details.audio',\n",
       "       'attributes.exception.message', 'attributes.llm.cost.total',\n",
       "       'start_time', 'attributes.agno.tools', 'attributes.session.id',\n",
       "       'attributes.graph.node.id', 'event.timestamps',\n",
       "       'attributes.llm.input_messages',\n",
       "       'attributes.llm.token_count.prompt_details.input', 'event.attributes',\n",
       "       'attributes.tool.description', 'attributes.llm.model_name',\n",
       "       'attributes.agent.name', 'attributes.llm.tools', 'status_message',\n",
       "       'attributes.tool.parameters',\n",
       "       'attributes.llm.token_count.completion_details.reasoning',\n",
       "       'attributes.llm.output_messages'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_RELEVANCY_PROMPT_TEMPLATE = \"\"\"\n",
    "You are comparing a reference text to a question and trying to determine if the reference text\n",
    "contains information relevant to answering the question. Here is the data:\n",
    "    [BEGIN DATA]\n",
    "    ************\n",
    "    [Question]: {{input}}\n",
    "    ************\n",
    "    [Reference text]: {{documents}}\n",
    "    ************\n",
    "    [END DATA]\n",
    "Compare the Question above to the Reference text. You must determine whether the Reference text\n",
    "contains information that can help answer the Question. First, write out in a step by step manner\n",
    "an EXPLANATION to show how to arrive at the correct answer. Avoid simply stating the correct answer\n",
    "at the outset. Your response LABEL must be single word, either \"relevant\" or \"unrelated\", and\n",
    "should not contain any text or characters aside from that word. \"unrelated\" means that the\n",
    "reference text does not help answer to the Question. \"relevant\" means the reference text directly\n",
    "answers the question.\n",
    "\n",
    "Example response:\n",
    "LABEL: \"relevant\" or \"unrelated\"\n",
    "************\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans_df = primary_df[\n",
    "    [\n",
    "        \"name\",\n",
    "        \"context.span_id\",\n",
    "        \"attributes.openinference.span.kind\",\n",
    "        \"context.trace_id\",\n",
    "        \"attributes.input.value\",\n",
    "        \"attributes.retrieval.documents\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>context.span_id</th>\n",
       "      <th>attributes.openinference.span.kind</th>\n",
       "      <th>context.trace_id</th>\n",
       "      <th>input</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RAG</td>\n",
       "      <td>0390d509c7879064</td>\n",
       "      <td>retriever</td>\n",
       "      <td>15e205614934c48ad1f2d44a65aaa57f</td>\n",
       "      <td>home organization under $50</td>\n",
       "      <td>[{'document.content': 'MaxProduct 2 in Home Or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RAG</td>\n",
       "      <td>b101ec77316ced40</td>\n",
       "      <td>retriever</td>\n",
       "      <td>df70b5d3c8f7f28863d774f450821922</td>\n",
       "      <td>home organization under $50</td>\n",
       "      <td>[{'document.content': 'MaxProduct 2 in Home Or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name   context.span_id attributes.openinference.span.kind  \\\n",
       "3  RAG  0390d509c7879064                          retriever   \n",
       "9  RAG  b101ec77316ced40                          retriever   \n",
       "\n",
       "                   context.trace_id                        input  \\\n",
       "3  15e205614934c48ad1f2d44a65aaa57f  home organization under $50   \n",
       "9  df70b5d3c8f7f28863d774f450821922  home organization under $50   \n",
       "\n",
       "                                           documents  \n",
       "3  [{'document.content': 'MaxProduct 2 in Home Or...  \n",
       "9  [{'document.content': 'MaxProduct 2 in Home Or...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = spans_df[\n",
    "    (spans_df[\"attributes.openinference.span.kind\"] == \"retriever\")\n",
    "    & (spans_df[\"attributes.retrieval.documents\"].notnull())\n",
    "]\n",
    "\n",
    "filtered_df = filtered_df.rename(\n",
    "    columns={\"attributes.input.value\": \"input\", \"attributes.retrieval.documents\": \"documents\"}\n",
    ")\n",
    "\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6e3f8ad5454053ac3b6dd7fbb44c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Dataframe |          | 0/2 (0.0%) | â³ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>context.span_id</th>\n",
       "      <th>attributes.openinference.span.kind</th>\n",
       "      <th>context.trace_id</th>\n",
       "      <th>input</th>\n",
       "      <th>documents</th>\n",
       "      <th>RAG Relevancy_execution_details</th>\n",
       "      <th>RAG Relevancy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RAG</td>\n",
       "      <td>0390d509c7879064</td>\n",
       "      <td>retriever</td>\n",
       "      <td>15e205614934c48ad1f2d44a65aaa57f</td>\n",
       "      <td>home organization under $50</td>\n",
       "      <td>[{'document.content': 'MaxProduct 2 in Home Or...</td>\n",
       "      <td>{'status': 'COMPLETED', 'exceptions': [], 'exe...</td>\n",
       "      <td>{'name': 'RAG Relevancy', 'score': 0.0, 'label...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RAG</td>\n",
       "      <td>b101ec77316ced40</td>\n",
       "      <td>retriever</td>\n",
       "      <td>df70b5d3c8f7f28863d774f450821922</td>\n",
       "      <td>home organization under $50</td>\n",
       "      <td>[{'document.content': 'MaxProduct 2 in Home Or...</td>\n",
       "      <td>{'status': 'COMPLETED', 'exceptions': [], 'exe...</td>\n",
       "      <td>{'name': 'RAG Relevancy', 'score': 0.0, 'label...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name   context.span_id attributes.openinference.span.kind  \\\n",
       "3  RAG  0390d509c7879064                          retriever   \n",
       "9  RAG  b101ec77316ced40                          retriever   \n",
       "\n",
       "                   context.trace_id                        input  \\\n",
       "3  15e205614934c48ad1f2d44a65aaa57f  home organization under $50   \n",
       "9  df70b5d3c8f7f28863d774f450821922  home organization under $50   \n",
       "\n",
       "                                           documents  \\\n",
       "3  [{'document.content': 'MaxProduct 2 in Home Or...   \n",
       "9  [{'document.content': 'MaxProduct 2 in Home Or...   \n",
       "\n",
       "                     RAG Relevancy_execution_details  \\\n",
       "3  {'status': 'COMPLETED', 'exceptions': [], 'exe...   \n",
       "9  {'status': 'COMPLETED', 'exceptions': [], 'exe...   \n",
       "\n",
       "                                 RAG Relevancy_score  \n",
       "3  {'name': 'RAG Relevancy', 'score': 0.0, 'label...  \n",
       "9  {'name': 'RAG Relevancy', 'score': 0.0, 'label...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openinference.instrumentation import suppress_tracing\n",
    "from phoenix.evals.evaluators import async_evaluate_dataframe\n",
    "from phoenix.evals.llm import LLM\n",
    "from phoenix.evals import create_classifier\n",
    "\n",
    "llm = LLM(provider=\"openai\", model=\"gpt-5\")\n",
    "\n",
    "relevancy_evaluator = create_classifier(\n",
    "    name=\"RAG Relevancy\",\n",
    "    llm=llm,\n",
    "    prompt_template=RAG_RELEVANCY_PROMPT_TEMPLATE,\n",
    "    choices={\"relevant\": 1.0, \"unrelated\": 0.0},\n",
    ")\n",
    "\n",
    "with suppress_tracing():\n",
    "    results_df = await async_evaluate_dataframe(\n",
    "        dataframe=filtered_df,\n",
    "        evaluators=[relevancy_evaluator],\n",
    "    )\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m  arize.utils.logging | INFO | The following columns do not follow the evaluation column naming convention and will be ignored: eval.rag.metadata, annotation_name and annotator_kind. Evaluation columns must be named as follows: - eval.<your-eval-name>.label- eval.<your-eval-name>.score- eval.<your-eval-name>.explanation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/77/0w3rw50s6_nc28qbf0hlwy2c0000gp/T/ipykernel_28427/1957919176.py:8: DeprecationWarning: Positional arguments for to_annotation_dataframe are deprecated and will be removed in a future version. Please use keyword arguments instead.\n",
      "  rag_eval_df = to_annotation_dataframe(results_df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m  arize.utils.logging | INFO | âœ… All 2 evaluation data have been logged successfully for model 'ecom-agent-eval-v4'!\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "records_updated: 2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arize.pandas.logger import Client\n",
    "from phoenix.evals.utils import to_annotation_dataframe\n",
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "client = Client()\n",
    "\n",
    "rag_eval_df = to_annotation_dataframe(results_df)\n",
    "rag_eval_df = rag_eval_df.rename(columns={\n",
    "    \"label\": \"eval.rag.label\",\n",
    "    \"score\": \"eval.rag.score\",\n",
    "    \"explanation\": \"eval.rag.explanation\",\n",
    "    \"metadata\": \"eval.rag.metadata\"\n",
    "})\n",
    "\n",
    "client.log_evaluations_sync(rag_eval_df, 'ecom-agent-eval-v4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on the retriever spans within each trace to view detailed evaluation results. You can also filter by evaluation outcome to quickly identify which queries successfully retrieved the most relevant documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  \n",
    "\n",
    "![My Image](images/Rag_Relevancy.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this section, we will walk you through how to set up and run evaluations in the Arize UI. Specifically, we will be running a trace level evaluation to determine the answer quality of our agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "![My Image](images/Untitled17.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "![My Image](images/Untitled18.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the project containing your traces, go to Eval Tasks and select LLM as a Judge.\n",
    "\n",
    "2. Name your task and schedule it to run on historical data. Each task can include multiple evaluators, but this walkthrough focuses on setting up one.\n",
    "\n",
    "3. Choose a trace-level evaluation.\n",
    "\n",
    "4. From the predefined templates, select Q&A or another template of your choice. You can also create a custom evaluation. If you define your own, ensure the variables align with your trace structure and specify the output labels (rails).\n",
    "\n",
    "5. Click Create Evals. Your evaluations will begin running and will appear on your existing traces. Look for the eval result on the top span for each trace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trace-Level Evaluation in the Arize UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![My Image](images/taskrun.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![My Image](images/evals.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Multi-Layered Evaluation**\n",
    "Updated evaluators for tool picking, response correctness, and tone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![My Image](images/correctnesscheck.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
