{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5PQim43vuwi"
   },
   "source": [
    "# **Trace your Scraping & Summarization Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8EbE_41szw0"
   },
   "source": [
    "In this lab, we will create an automatic web scraping and summarization agent powered by the Agno framework and OpenAI models. We‚Äôll begin by installing the necessary OpenInference packages and setting up tracing with Arize.\n",
    "\n",
    "Next, we‚Äôll define tools that search the web, extract article content, and identify key entities.\n",
    "\n",
    "Finally, we‚Äôll build and run our agent, viewing the resulting trace outputs in Arize to understand how the agent uses its tools to synthesize a comprehensive summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gxe7vsT9hKHX"
   },
   "source": [
    "You will need a free Arize account, an OpenAI API key, and a free [Tavily](https://auth.tavily.com/) API Key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzvQoYIksr30"
   },
   "source": [
    "# Set up keys and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XtfV7qF6HKg"
   },
   "outputs": [],
   "source": [
    "!pip install -qqqqqq arize-otel agno openai openinference-instrumentation-agno openinference-instrumentation-openai httpx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîê Account Setup & API Keys\n",
    "\n",
    "Before building your **Agentic Flow**, you'll need API access for three key services:\n",
    "\n",
    "- **[Arize AI](https://arize.com/signup/)** ‚Äî for tracing, metrics, and observability  \n",
    "- **[Tavily](https://tavily.com/)** ‚Äî for search and web scraping  \n",
    "- **[OpenAI](https://platform.openai.com/signup)** ‚Äî for LLM inference (e.g., GPT-4o)\n",
    "\n",
    "Once registered, collect your API keys from each platform‚Äôs dashboard.  \n",
    "To keep credentials secure and reusable across sessions, we'll store them as **environment variables**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hAapTFAi-35H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"ARIZE_SPACE_ID\"] = globals().get(\"ARIZE_SPACE_ID\") or getpass(\"üîë Enter your Arize Space ID: \")\n",
    "\n",
    "os.environ[\"ARIZE_API_KEY\"] = globals().get(\"ARIZE_API_KEY\") or getpass(\"üîë Enter your Arize API Key: \")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = globals().get(\"OPENAI_API_KEY\") or getpass(\"üîë Enter your OpenAI API Key: \")\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = globals().get(\"TAVILY_API_KEY\") or getpass(\"üîë Enter your Tavily API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFdPHLMFuEsl"
   },
   "source": [
    "# Setup tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Y8dSorscJDPT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Arize Project: scraping-summarization-demo\n",
      "|  Span Processor: BatchSpanProcessor\n",
      "|  Collector Endpoint: otlp.arize.com\n",
      "|  Transport: gRPC\n",
      "|  Transport Headers: {'authorization': '****', 'api_key': '****', 'arize-space-id': '****', 'space_id': '****', 'arize-interface': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from arize.otel import register\n",
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "from openinference.instrumentation.agno import AgnoInstrumentor\n",
    "\n",
    "model_id = \"scraping-summarization-demo\"\n",
    "tracer_provider = register(\n",
    "    space_id=os.getenv(\"ARIZE_SPACE_ID\"),\n",
    "    api_key=os.getenv(\"ARIZE_API_KEY\"),\n",
    "    project_name=model_id,\n",
    "    set_global_tracer_provider=True\n",
    ")\n",
    "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)\n",
    "AgnoInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AJ6qnPvOmKG-"
   },
   "outputs": [],
   "source": [
    "from opentelemetry import trace\n",
    "tracer = trace.get_tracer(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gjd7wU9OuIAQ"
   },
   "source": [
    "# Define Scraping Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnRbOa8tg_B7"
   },
   "source": [
    "We use Tavily Search as a lightweight scraper to gather general information, news, and entities across the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "H3gLnYV2_KhS"
   },
   "outputs": [],
   "source": [
    "# --- Helper functions for tools ---\n",
    "import httpx\n",
    "\n",
    "def _scrape_api(query: str, search_depth: str = \"basic\") -> str | None:\n",
    "    \"\"\"Use Tavily search to fetch and scrape web content snippets.\"\"\"\n",
    "    tavily_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "    if not tavily_key:\n",
    "        return None\n",
    "    try:\n",
    "        resp = httpx.post(\n",
    "            \"https://api.tavily.com/search\",\n",
    "            json={\n",
    "                \"api_key\": tavily_key,\n",
    "                \"query\": query,\n",
    "                \"max_results\": 4,\n",
    "                \"search_depth\": search_depth,\n",
    "                \"include_answer\": True,\n",
    "            },\n",
    "            timeout=10,\n",
    "        )\n",
    "        data = resp.json()\n",
    "        answer = data.get(\"answer\") or \"\"\n",
    "        snippets = [r.get(\"content\", \"\") for r in data.get(\"results\", [])]\n",
    "        combined = \" \".join([answer] + snippets).strip()\n",
    "        return combined[:600] if combined else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _compact(text: str, limit: int = 300) -> str:\n",
    "    \"\"\"Compact text for cleaner outputs.\"\"\"\n",
    "    cleaned = \" \".join(text.split())\n",
    "    return cleaned if len(cleaned) <= limit else cleaned[:limit].rsplit(\" \", 1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tNgVS4Fk_QRR"
   },
   "outputs": [],
   "source": [
    "from agno.tools import tool\n",
    "\n",
    "@tool\n",
    "def scrape_latest_news(topic: str) -> str:\n",
    "    \"\"\"Scrape the web for the latest news headlines and breakthroughs about a topic.\"\"\"\n",
    "    q = f\"{topic} latest news breakthroughs announcements\"\n",
    "    s = _scrape_api(q, search_depth=\"advanced\")\n",
    "    if s:\n",
    "        return f\"Latest news on {topic}: {_compact(s, 400)}\"\n",
    "    return f\"Could not fetch latest news for {topic}.\"\n",
    "\n",
    "@tool\n",
    "def deep_dive_research(topic: str) -> str:\n",
    "    \"\"\"Perform in-depth web research to extract detailed facts, mechanisms, and context.\"\"\"\n",
    "    q = f\"{topic} comprehensive overview how it works detailed analysis\"\n",
    "    s = _scrape_api(q)\n",
    "    if s:\n",
    "        return f\"Deep dive research on {topic}: {_compact(s, 500)}\"\n",
    "    return f\"Detailed research currently unavailable for {topic}.\"\n",
    "\n",
    "@tool\n",
    "def extract_key_entities(topic: str) -> str:\n",
    "    \"\"\"Identify key companies, organizations, or leading figures associated with the topic.\"\"\"\n",
    "    q = f\"{topic} top companies key players leading researchers\"\n",
    "    s = _scrape_api(q)\n",
    "    if s:\n",
    "        return f\"Key entities for {topic}: {_compact(s, 300)}\"\n",
    "    return f\"No specific entities found for {topic}.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o48IXEMJuJuI"
   },
   "source": [
    "# Define Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Sb1jqHcU_R3r"
   },
   "outputs": [],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "\n",
    "# --- Main Agent ---\n",
    "research_agent = Agent(\n",
    "    name=\"ResearchSummarizer\",\n",
    "    role=\"AI Research & Summarization Analyst\",\n",
    "    model=OpenAIChat(id=\"gpt-4o\"),\n",
    "    instructions=(\n",
    "        \"You are an expert research analyst. \"\n",
    "        \"Use your tools to scrape the web and gather comprehensive information on the requested topic. \"\n",
    "        \"Synthesize the extracted data into a well-structured summary. \"\n",
    "        \"Include a 'High-Level Summary', 'Key Findings', 'Key Players', and 'Future Outlook'. \"\n",
    "        \"Keep the tone professional, objective, and clear.\"\n",
    "    ),\n",
    "    markdown=True,\n",
    "    tools=[scrape_latest_news, deep_dive_research, extract_key_entities],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAKB1WBwuLh2"
   },
   "source": [
    "# Run agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FVDKZT9x_U-5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16160acfc179403199e0aede7cfb425f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Example usage ---\n",
    "topic = \"Solid-State Batteries for Electric Vehicles\"\n",
    "focus = \"latest technological breakthroughs and timeline to market\"\n",
    "\n",
    "query = f\"\"\"\n",
    "Conduct a comprehensive web search and summarization on {topic}.\n",
    "Focus specifically on {focus}.\n",
    "Provide a structured report with your findings.\n",
    "\"\"\"\n",
    "research_agent.print_response(\n",
    "    query,\n",
    "    stream = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4LPN8-guQSx"
   },
   "source": [
    "# Observe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OS_gOmfLvIi-"
   },
   "source": [
    "Log into Arize to track the tool usage, observe exactly what context Tavily scraped from the web, and evaluate the LLM's capability to summarize those outputs successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe src=\"https://drive.google.com/file/d/15s4mmQIet5WtlLoE9CRu6sdl3NUwID2H/preview\" \n",
       "        width=\"100%\" \n",
       "        height=\"500\" \n",
       "        style=\"border: none;\">\n",
       "    <a href=\"https://drive.google.com/file/d/15s4mmQIet5WtlLoE9CRu6sdl3NUwID2H/view\" target=\"_blank\">View Agent Trace (opens in new tab)</a>\n",
       "</iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "url = \"https://drive.google.com/file/d/15s4mmQIet5WtlLoE9CRu6sdl3NUwID2H/view\"\n",
    "embed_url = url.replace(\"/view\", \"/preview\")  # Google Drive preview mode\n",
    "\n",
    "html = f'''\n",
    "<iframe src=\"{embed_url}\" \n",
    "        width=\"100%\" \n",
    "        height=\"500\" \n",
    "        style=\"border: none;\">\n",
    "    <a href=\"{url}\" target=\"_blank\">View Agent Trace (opens in new tab)</a>\n",
    "</iframe>\n",
    "'''\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Benefits of Tracing in Arize\n",
    "\n",
    "**Debug Traces**  \n",
    "Enables you to quickly identify and troubleshoot errors within your application's execution flow.\n",
    "\n",
    "**Analyze Root Causes**  \n",
    "Helps in pinpointing exactly why a specific issue occurred by providing a granular look at the data flow.\n",
    "\n",
    "**Performance Optimization**  \n",
    "Allows you to identify latency bottlenecks and optimize LLM calls or tool execution times.\n",
    "\n",
    "**Evaluation & Quality Assurance**  \n",
    "Provides the necessary data to run evaluations on traces to ensure the accuracy and quality of outputs.\n",
    "\n",
    "**Sustainability & Cost Tracking**  \n",
    "Offers visibility into resource usage (like token counts and costs shown in the header) to manage the efficiency of the system.\n",
    "\n",
    "**Error Detection**  \n",
    "Automatically catches and flags errors across different \"spans\" (steps) of the AI's process.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Key Tracing Features Visible\n",
    "\n",
    "**Trace Tree/Agent Graph**  \n",
    "A visual hierarchy of how your AI agent moved from a research summarizer to specific tool calls (like scrape_latest_news).\n",
    "\n",
    "**Input/Output Inspection**  \n",
    "The ability to see the exact JSON payload sent to a tool and the resulting output.\n",
    "\n",
    "**Cost Monitoring**  \n",
    "Real-time tracking of the total cost for a specific trace (e.g., $0.016425).\n",
    "\n",
    "**Latency Tracking**  \n",
    "Time stamps for every individual step (e.g., 4.77s for a scrape)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
